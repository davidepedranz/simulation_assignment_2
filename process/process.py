#!/usr/bin/env python

import os
import sys
from collections import OrderedDict
from pandas import DataFrame, concat, read_csv, read_hdf
import matplotlib as mpl

mpl.use('Agg')
import matplotlib.pyplot as plt

# possible packet states
# NB: make sure this codes match to the one used by the Log class
PKT_RECEIVING = 0
PKT_RECEIVED = 1
PKT_CORRUPTED = 2
PKT_CORRUPTED_BY_CHANNEL = 3
PKT_GENERATED = 10
PKT_QUEUE_DROPPED = 11


def is_number(string):
    """
    Determine whether a string contains a number.
    """
    try:
        float(string)
        return True
    except ValueError:
        return False


def get_data_files(folder, suffix=".csv"):
    """
    Gets the list of files with a certain prefix and suffix in a folder.
    """
    files_list = []
    for f in os.listdir(folder):
        if f.endswith(suffix):
            files_list.append(f)
    return files_list


def parse_file_name(name):
    """
    Parse the name of a CSV file generated by a run of the simulator,
    according to the following format: 'output_{simulator}_{lambda}_{seed}.csv'
    :param name: Name of the file.
    :return: Dictionary of the parameters used to run the simulation.
    """
    tokens = os.path.splitext(name)[0].split("_")
    return {
        'simulator': tokens[1],
        'lambda': float(tokens[2]),
        'seed': float(tokens[3])
    }


def offered_load(l, n_nodes, packet_size=(1460 + 32) / 2):
    """
    Total offered load in Mbps.
    'l' is the Lambda parameter of the distribution (packets / s).
    """
    assert is_number(l)
    return l * n_nodes * packet_size * 8 / 1024 / 1024


def statistics(x, sim_time, load):
    """
    Computes throughput, collision rate and drop rate for a specific node
    and a specific simulation.
    :param x Dataframe for a single node.
    :param sim_time Total simulation time.
    :param load Load offered for this simulation.
    """

    rcv_packets_df = x.loc[x.event == PKT_RECEIVED]

    # number of packets for each type
    rcv_packets = len(rcv_packets_df)
    crp_packets = len(x.loc[x.event == PKT_CORRUPTED])
    crp_ch_packets = len(x.loc[x.event == PKT_CORRUPTED_BY_CHANNEL])
    gen_packets = len(x.loc[x.event == PKT_GENERATED])
    drp_packets = len(x.loc[x.event == PKT_QUEUE_DROPPED])
    inc_packets = rcv_packets + crp_packets + crp_ch_packets

    # return the statistics
    return DataFrame(OrderedDict({
        'tr': [rcv_packets_df['size'].sum() * 8 / sim_time / 1024 ** 2],
        'cr': [float(crp_packets) / inc_packets],
        'dr': [float(drp_packets) / gen_packets],
        'cc': [float(crp_ch_packets) / inc_packets],
        'load': load
    }))


def compute_stats_single_run(dataframe, lambda_par):
    """
    Compute the statistics for a single run of the simulator.
    :param dataframe: Pandas Dataframe with the raw data (CSV file).
    :param lambda_par: Lambda parameter.
    :return: Statistics for this run.
    """
    n_nodes = len(dataframe['dst'].unique())
    load = offered_load(lambda_par, n_nodes)
    stats = dataframe.groupby('dst').apply(
        lambda x: statistics(x, dataframe.time.max(), load))
    stats_no_index = stats.reset_index(level=1, drop=True).reset_index()
    return stats_no_index


def process_csv_raw_files(folder):
    """
    Compute the statistics for a single run of the simulator.
    :param folder: Folder where the raw CSV files are stored.
    :return: Statistics as a Pandas Dataframe.
    """

    # store all statistics in memory
    all_statistics = DataFrame()

    # get the list of files
    files = get_data_files(folder, ".csv")

    # compute the statistics one run at a time
    for i, f in enumerate(files):
        print ('  -> Analyze simulation %i of %i' % (i + 1, len(files)))

        # parse the parameters
        params = parse_file_name(f)

        # read the CSV
        current_csv = read_csv("%s/%s" % (folder, f))

        # compute statistics
        current_stats = compute_stats_single_run(current_csv, params['lambda'])

        # add columns
        current_stats.insert(0, 'simulator', params['simulator'])
        current_stats['lambda'] = params['lambda']
        current_stats['seed'] = params['seed']

        # save statistics
        all_statistics = concat([all_statistics, current_stats])

    # return the statistics for all files
    return all_statistics.reset_index(drop=True)


def plot_individual_metric(nodes, loads, metrics, path, title, y_label,
                           y_lim=(0, 1.05)):
    figure = plt.figure()
    ax = figure.add_subplot(111)
    for (node, metric) in zip(nodes, metrics):
        ax.plot(loads, metric, label=str(node), marker='o')
    ax.set_title(title, fontsize=16, y=1.02)
    ax.legend(shadow=True, loc='center left', bbox_to_anchor=(1.02, 0.5))
    box = ax.get_position()
    ax.set_position([box.x0, box.y0, box.width * 0.92, box.height])
    ax.set_xlabel('Total offered load (Mbps)')
    ax.set_ylabel(y_label)
    ax.set_ylim(y_lim)
    ax.grid(True)
    figure.savefig(path)
    plt.close(figure)


def plot_individual_statistic(stat, folder):
    # process each version of the simulator independently from each other
    versions = stat.simulator.unique()
    for v in versions:

        # extract current data
        df = stat.query('simulator=="' + v + '"')

        # x-axis: lambda ... load on network
        loads = list(df['load'].unique())

        # accumulators for the metrics
        crs = []
        drs = []
        trs = []
        ccs = []

        # extract nodes and metrics for each node
        nodes = df['dst'].unique()
        for n in nodes:
            crs.append(list(df.query('dst==' + str(n))['cr']))
            drs.append(list(df.query('dst==' + str(n))['dr']))
            trs.append(list(df.query('dst==' + str(n))['tr']))
            ccs.append(list(df.query('dst==' + str(n))['cc']))

        # plot the 3 metrics
        base = '0_plot_%s_' % v
        plot_individual_metric(nodes, loads, crs, folder + base + 'crs.png',
                               'Collision Rate',
                               'Collision rate at receiver (Mbps)')
        plot_individual_metric(nodes, loads, drs, folder + base + 'drs.png',
                               'Packet Drop Rate',
                               'Packet drop rate at the sender')
        plot_individual_metric(nodes, loads, trs, folder + base + 'trs.png',
                               'Throughput', 'Throughput at receiver (Mbps)',
                               y_lim=(0, 3))
        plot_individual_metric(nodes, loads, ccs, folder + base + 'ccs.png',
                               'Channel Corruption Rate',
                               'Channel corruption rate (Mbps)')


def aggregate_statistics(stats, folder):
    print("Aggregated stats by simulator and load ... \n")

    # aggregate by simulator version and load
    agg = stats.groupby(['simulator', 'load'], as_index=False).agg({
        'cr': {
            'cr_mean': 'mean'
        },
        'dr': {
            'dr_mean': 'mean'
        },
        'tr': {
            'tr_mean': 'mean'
        },
        'cc': {
            'cc_mean': 'mean'
        }
    })

    # remove multi-index from columns
    agg.columns = agg.columns.droplevel(1)

    # plots
    versions = agg.simulator.unique()
    loads = []
    crs = []
    drs = []
    trs = []
    ccs = []

    # extract metrics for each simulator
    for v in versions:
        # extract current data
        df = agg.query('simulator=="' + v + '"')

        # extract metrics
        loads.append(list(df['load']))
        crs.append(list(df['cr']))
        drs.append(list(df['dr']))
        trs.append(list(df['tr']))
        ccs.append(list(df['cc']))

    # plot
    base = '1_compare_simulators_'
    plot_aggregated_metric(versions, loads, crs, folder + base + 'crs.png',
                           'Collision Rate',
                           'Collision rate at receiver (Mbps)')
    plot_aggregated_metric(versions, loads, drs, folder + base + 'drs.png',
                           'Packet Drop Rate',
                           'Packet drop rate at the sender')
    plot_aggregated_metric(versions, loads, trs, folder + base + 'trs.png',
                           'Throughput', 'Throughput at receiver (Mbps)',
                           y_lim=(0, 3))
    plot_aggregated_metric(versions, loads, ccs, folder + base + 'ccs.png',
                           'Channel Corruption Rate',
                           'Channel corruption rate (Mbps)')

    return agg


def plot_aggregated_metric(versions, loads, metrics, path, title, y_label,
                           y_lim=(0, 1.05)):
    figure = plt.figure()
    ax = figure.add_subplot(111)
    for (v, l, m) in zip(versions, loads, metrics):
        ax.plot(l, m, label=str(v), marker='o')
    ax.set_title(title, fontsize=16, y=1.02)
    ax.legend(shadow=True, loc='upper center', bbox_to_anchor=(0.5, -0.18),
              ncol=3)
    box = ax.get_position()
    ax.set_position(
        [box.x0, box.y0 + box.height * 0.15, box.width, box.height * 0.85])
    ax.set_xlabel('Total offered load (Mbps)')
    ax.set_ylabel(y_label)
    ax.set_ylim(y_lim)
    ax.grid(True)
    figure.savefig(path)
    plt.close(figure)


def main():
    """
    Process the data generated by one or more versions of the simulator.
    """

    # compute the location of the CSV files
    __location__ = os.path.realpath(
        os.path.join(os.getcwd(), os.path.dirname(__file__)))
    folder = os.path.join(__location__, "../output/")

    # ... or read it as a parameter of the script
    if len(sys.argv) != 1:
        folder = sys.argv[1]

    # compute the statistics
    # use cache if available, otherwise load data from raw CSV
    aggregated_file = "%s/000_cache.h5" % folder
    if not os.path.isfile(aggregated_file):
        print('Loading CSV files...')
        all_statistics = process_csv_raw_files(folder)
        all_statistics.to_hdf(aggregated_file, 'fixed')
    else:
        print('Using cached statistics...')
        all_statistics = read_hdf(aggregated_file)

    # store statistics in a file
    all_statistics.to_hdf('%s/summary.h5' % folder, 'table')

    # get rid of the seeds (take the average over all seeds)
    mean_stats = all_statistics \
        .groupby(['simulator', 'dst', 'load', 'lambda'], as_index=False) \
        .mean() \
        .reset_index(level=3, drop=True) \
        .drop('seed', 1)

    # plot graphs for each simulator
    plot_individual_statistic(mean_stats, folder)

    # compute aggregated statistic for each version of the simulator
    pro = aggregate_statistics(all_statistics, folder)
    print(pro)


# entry point
if __name__ == '__main__':
    main()
